__author__ = "Jumperkables"
"""
Generated by ChatGPT
"""
import os, sys
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.datasets import ImageFolder
import pytorch_lightning as pl

#os.environ["CUDA_LAUNCH_BLOCKING"] = "1"
DATA_DIR = f"data/isic_subset_cleaned"
NUM_CLASSES = len(os.listdir(DATA_DIR))
NUM_HEADS = 4
BATCH_SIZE = 16
ORTHOGONALITY_INTENSITY = 0.2

class SkinLesionClassifier(pl.LightningModule):
    def __init__(self):
        super(SkinLesionClassifier, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        for x in range(NUM_HEADS):
            head = nn.Sequential(
                nn.Linear(512 * 14 * 14, 512),
                nn.ReLU(inplace=True),
                nn.Dropout(0.5),
                nn.Linear(512, NUM_CLASSES),
            )
            setattr(self, f"head_{x}", head)
            #setattr(self, f"criterion_{x}", nn.CrossEntropyLoss())
        self.criterion = nn.CrossEntropyLoss()

    def forward(self, x):
        x = self.features(x)
        x = torch.flatten(x, 1)
        h_output = torch.zeros(x.shape[0], NUM_CLASSES).to(x.device)
        h_outputs = []
        for i in range(NUM_HEADS):
            h_out = getattr(self, f"head_{i}")(x)
            h_output += h_out
            h_outputs.append(h_out)
        # Calculate vector similarity, and penalise to enforce orthogonality 
        dot_prods = []
        saliencies = []
        for i in range(NUM_HEADS):
            # Enforce saliency to become concentrated
            chosen_classes = torch.argmax(h_outputs[i], dim=0)

            breakpoint()
            h_outputs[i][0, chosen_classes] # Get the highest voted class for each element in the batch
            for j in range(NUM_HEADS):
                if i != j:
                    dim_0 = h_outputs[i].shape[0]
                    dim_1 = h_outputs[i].shape[1]
                    dp = torch.bmm( h_outputs[i].view(dim_0, 1, dim_1), h_outputs[j].view(dim_0, dim_1, 1) )
                    dp = dp.squeeze(1).squeeze(1)
                    dot_prods.append(dp)
        dot_prods = sum(dot_prods)
        return h_output, dot_prods, saliencies

    def training_step(self, batch, batch_idx):
        images, labels = batch
        h_output, dot_prods, saliencies = self(images)
        loss = self.criterion(h_output, labels)
        loss += sum(dot_prods)
        self.log("train_loss", loss)
        return loss

    def validation_step(self, batch, batch_idx):
        images, labels = batch
        h_output, dot_prods, saliencies = self(images)
        breakpoint()
        loss = self.criterion(h_output, labels)
        loss += sum(dot_prods)
        self.log("val_loss", loss)

    def configure_optimizers(self):
        return optim.Adam(self.parameters(), lr=0.001)

# Set transforms for data augmentation
data_transforms = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Load the dataset
dataset = ImageFolder(DATA_DIR, transform=data_transforms)
train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size
train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

# Initialize the Lightning module
skin_classifier = SkinLesionClassifier()

# Create a PyTorch Lightning trainer
trainer = pl.Trainer(max_epochs=10, num_nodes=1, accelerator="gpu") #gpus=1 if torch.cuda.is_available() else 0)

# Train the model
trainer.fit(skin_classifier, train_loader, test_loader)
